{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import gzip\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from os import mkdir \n",
    "from shutil import move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruslan_Golubev\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#adding this to avoid memory errors\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ruslan_Golubev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ruslan_Golubev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ruslan_Golubev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_non_letters(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = \"\".join(c for c in word if c.isalpha())\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def delete_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english') and word not in stopwords.words('russian'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(text, tokenized=False, del_stopwords=False):\n",
    "    if not tokenized:\n",
    "        text = nltk.word_tokenize(text)\n",
    "    \n",
    "    text = delete_non_letters(text)\n",
    "    if del_stopwords:\n",
    "        text = delete_stopwords(text)\n",
    "        \n",
    "    text = to_lowercase(text)\n",
    "    \n",
    "    text = [word for word in text if len(word) > 1]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv(r'C:\\Users\\Ruslan_Golubev\\Documents\\VK_EPAM_TA_SEARCH\\text_3m.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего пока имеем 20499 постов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data_full['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['наш с каждым днём всё более гуманный суд пришёл за гей-пабликами - как тут не подписаться.\\n\\n(а также прекрасное обращение \"уважаемые солнышки\", надо запомнить)',\n",
       " 'Ух, ты... Common practice...\\n\\n In e-group on Monday October 15, 2019 we took the decision to enable a \"job family country-of-residence block\" for team members who have access to customer data. This is at the expressed concern of several enterprise customers, and also what is becoming a common practice in our industry in the current geopolitical climate.\\n\\nThe countries involved are:\\n\\nChina\\nRussia',\n",
       " 'А давайте тот же опрос, вид сбоку.',\n",
       " 'опрос идеологический',\n",
       " 'Аэропорт Лаппенранты летает только в аэропорта на букву Б. Поэтому Афины оттуда исключили, как расово-неверный маршрут.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(data_full['text'])\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Как видно по первым постам, нам будут встречаться очень короткие, не несущие смысловой нагрузки посты.\n",
    "Обработаем их. (lowercase, stop_words, non_letters, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lens = []\n",
    "text_proc = []\n",
    "for sent in corpus:\n",
    "    tok_sent = nltk.word_tokenize(sent)\n",
    "    tok_sent = normalize(tok_sent, tokenized=True)\n",
    "    text_lens.append(len(tok_sent))\n",
    "    text_proc.append(tok_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И выведем гистограмму длинн постов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 3))\n",
    "ax=fig.add_subplot(111)\n",
    "plt.hist(text_lens, bins=[i  for i in range(int(50000/100))])\n",
    "ax.set_xlim(xmin=0.0, xmax=300)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(text_lens) < 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_texts = []\n",
    "long_texts = []\n",
    "for i in range(len(mask)):\n",
    "    if mask[i]:\n",
    "        short_texts.append(text_proc[i])\n",
    "    else:\n",
    "        long_texts.append(text_proc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4490"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16009"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим на трейн и тест наш оригинальный корпус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(corpus, test_size = 0.1, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stopwords = ['China', 'Common', 'In', 'Monday', 'October', 'Russia', 'The', 'This', 'access', 'also', 'becoming', 'block', 'climate', 'common', 'concern', 'country', 'country-of-residence', 'current', 'customer', 'data', 'decision', 'e-group', 'enable', 'enterprise', 'expressed', 'family', 'geopolitical', 'industry', 'involved', 'job', 'member', 'practice', 'several', 'team', 'took', 'Ух','arent', 'couldnt', 'didnt', 'doe', 'doesnt', 'dont', 'ha', 'hadnt', 'hasnt', 'havent', 'isnt', 'mightnt', 'mustnt', 'neednt', 'shant', 'shes', 'shouldnt', 'shouldve', 'thatll', 'wa', 'wasnt', 'werent', 'wont', 'wouldnt', 'youd', 'youll', 'youre', 'youve', 'хотел',\"c\",\"а\",\"алло\",\"без\",\"белый\",\"близко\",\"более\",\"больше\",\"большой\",\"будем\",\"будет\",\"будете\",\"будешь\",\"будто\",\"буду\",\"будут\",\"будь\",\"бы\",\"бывает\",\"бывь\",\"был\",\"была\",\"были\",\"было\",\"быть\",\"в\",\"важная\",\"важное\",\"важные\",\"важный\",\"вам\",\"вами\",\"вас\",\"ваш\",\"ваша\",\"ваше\",\"ваши\",\"вверх\",\"вдали\",\"вдруг\",\"ведь\",\"везде\",\"вернуться\",\"весь\",\"вечер\",\"взгляд\",\"взять\",\"вид\",\"видел\",\"видеть\",\"вместе\",\"вне\",\"вниз\",\"внизу\",\"во\",\"вода\",\"война\",\"вокруг\",\"вон\",\"вообще\",\"вопрос\",\"восемнадцатый\",\"восемнадцать\",\"восемь\",\"восьмой\",\"вот\",\"впрочем\",\"времени\",\"время\",\"все\",\"все еще\",\"всегда\",\"всего\",\"всем\",\"всеми\",\"всему\",\"всех\",\"всею\",\"всю\",\"всюду\",\"вся\",\"всё\",\"второй\",\"вы\",\"выйти\",\"г\",\"где\",\"главный\",\"глаз\",\"говорил\",\"говорит\",\"говорить\",\"год\",\"года\",\"году\",\"голова\",\"голос\",\"город\",\"да\",\"давать\",\"давно\",\"даже\",\"далекий\",\"далеко\",\"дальше\",\"даром\",\"дать\",\"два\",\"двадцатый\",\"двадцать\",\"две\",\"двенадцатый\",\"двенадцать\",\"дверь\",\"двух\",\"девятнадцатый\",\"девятнадцать\",\"девятый\",\"девять\",\"действительно\",\"дел\",\"делал\",\"делать\",\"делаю\",\"дело\",\"день\",\"деньги\",\"десятый\",\"десять\",\"для\",\"до\",\"довольно\",\"долго\",\"должен\",\"должно\",\"должный\",\"дом\",\"дорога\",\"друг\",\"другая\",\"другие\",\"других\",\"друго\",\"другое\",\"другой\",\"думать\",\"душа\",\"е\",\"его\",\"ее\",\"ей\",\"ему\",\"если\",\"есть\",\"еще\",\"ещё\",\"ею\",\"её\",\"ж\",\"ждать\",\"же\",\"жена\",\"женщина\",\"жизнь\",\"жить\",\"за\",\"занят\",\"занята\",\"занято\",\"заняты\",\"затем\",\"зато\",\"зачем\",\"здесь\",\"земля\",\"знать\",\"значит\",\"значить\",\"и\",\"иди\",\"идти\",\"из\",\"или\",\"им\",\"имеет\",\"имел\",\"именно\",\"иметь\",\"ими\",\"имя\",\"иногда\",\"их\",\"к\",\"каждая\",\"каждое\",\"каждые\",\"каждый\",\"кажется\",\"казаться\",\"как\",\"какая\",\"какой\",\"кем\",\"книга\",\"когда\",\"кого\",\"ком\",\"комната\",\"кому\",\"конец\",\"конечно\",\"которая\",\"которого\",\"которой\",\"которые\",\"который\",\"которых\",\"кроме\",\"кругом\",\"кто\",\"куда\",\"лежать\",\"лет\",\"ли\",\"лицо\",\"лишь\",\"лучше\",\"любить\",\"люди\",\"м\",\"маленький\",\"мало\",\"мать\",\"машина\",\"между\",\"меля\",\"менее\",\"меньше\",\"меня\",\"место\",\"миллионов\",\"мимо\",\"минута\",\"мир\",\"мира\",\"мне\",\"много\",\"многочисленная\",\"многочисленное\",\"многочисленные\",\"многочисленный\",\"мной\",\"мною\",\"мог\",\"могу\",\"могут\",\"мож\",\"может\",\"может быть\",\"можно\",\"можхо\",\"мои\",\"мой\",\"мор\",\"москва\",\"мочь\",\"моя\",\"моё\",\"мы\",\"на\",\"наверху\",\"над\",\"надо\",\"назад\",\"наиболее\",\"найти\",\"наконец\",\"нам\",\"нами\",\"народ\",\"нас\",\"начала\",\"начать\",\"наш\",\"наша\",\"наше\",\"наши\",\"не\",\"него\",\"недавно\",\"недалеко\",\"нее\",\"ней\",\"некоторый\",\"нельзя\",\"нем\",\"немного\",\"нему\",\"непрерывно\",\"нередко\",\"несколько\",\"нет\",\"нею\",\"неё\",\"ни\",\"нибудь\",\"ниже\",\"низко\",\"никакой\",\"никогда\",\"никто\",\"никуда\",\"ним\",\"ними\",\"них\",\"ничего\",\"ничто\",\"но\",\"новый\",\"нога\",\"ночь\",\"ну\",\"нужно\",\"нужный\",\"нх\",\"о\",\"об\",\"оба\",\"обычно\",\"один\",\"одиннадцатый\",\"одиннадцать\",\"однажды\",\"однако\",\"одного\",\"одной\",\"оказаться\",\"окно\",\"около\",\"он\",\"она\",\"они\",\"оно\",\"опять\",\"особенно\",\"остаться\",\"от\",\"ответить\",\"отец\",\"откуда\",\"отовсюду\",\"отсюда\",\"очень\",\"первый\",\"перед\",\"писать\",\"плечо\",\"по\",\"под\",\"подойди\",\"подумать\",\"пожалуйста\",\"позже\",\"пойти\",\"пока\",\"пол\",\"получить\",\"помнить\",\"понимать\",\"понять\",\"пор\",\"пора\",\"после\",\"последний\",\"посмотреть\",\"посреди\",\"потом\",\"потому\",\"почему\",\"почти\",\"правда\",\"прекрасно\",\"при\",\"про\",\"просто\",\"против\",\"процентов\",\"путь\",\"пятнадцатый\",\"пятнадцать\",\"пятый\",\"пять\",\"работа\",\"работать\",\"раз\",\"разве\",\"рано\",\"раньше\",\"ребенок\",\"решить\",\"россия\",\"рука\",\"русский\",\"ряд\",\"рядом\",\"с\",\"с кем\",\"сам\",\"сама\",\"сами\",\"самим\",\"самими\",\"самих\",\"само\",\"самого\",\"самой\",\"самом\",\"самому\",\"саму\",\"самый\",\"свет\",\"свое\",\"своего\",\"своей\",\"свои\",\"своих\",\"свой\",\"свою\",\"сделать\",\"сеаой\",\"себе\",\"себя\",\"сегодня\",\"седьмой\",\"сейчас\",\"семнадцатый\",\"семнадцать\",\"семь\",\"сидеть\",\"сила\",\"сих\",\"сказал\",\"сказала\",\"сказать\",\"сколько\",\"слишком\",\"слово\",\"случай\",\"смотреть\",\"сначала\",\"снова\",\"со\",\"собой\",\"собою\",\"советский\",\"совсем\",\"спасибо\",\"спросить\",\"сразу\",\"стал\",\"старый\",\"стать\",\"стол\",\"сторона\",\"стоять\",\"страна\",\"суть\",\"считать\",\"т\",\"та\",\"так\",\"такая\",\"также\",\"таки\",\"такие\",\"такое\",\"такой\",\"там\",\"твои\",\"твой\",\"твоя\",\"твоё\",\"те\",\"тебе\",\"тебя\",\"тем\",\"теми\",\"теперь\",\"тех\",\"то\",\"тобой\",\"тобою\",\"товарищ\",\"тогда\",\"того\",\"тоже\",\"только\",\"том\",\"тому\",\"тот\",\"тою\",\"третий\",\"три\",\"тринадцатый\",\"тринадцать\",\"ту\",\"туда\",\"тут\",\"ты\",\"тысяч\",\"у\",\"увидеть\",\"уж\",\"уже\",\"улица\",\"уметь\",\"утро\",\"хороший\",\"хорошо\",\"хотел бы\",\"хотеть\",\"хоть\",\"хотя\",\"хочешь\",\"час\",\"часто\",\"часть\",\"чаще\",\"чего\",\"человек\",\"чем\",\"чему\",\"через\",\"четвертый\",\"четыре\",\"четырнадцатый\",\"четырнадцать\",\"что\",\"чтоб\",\"чтобы\",\"чуть\",\"шестнадцатый\",\"шестнадцать\",\"шестой\",\"шесть\",\"эта\",\"эти\",\"этим\",\"этими\",\"этих\",\"это\",\"этого\",\"этой\",\"этом\",\"этому\",\"этот\",\"эту\",\"я\",\"являюсь\"]\n",
    "stopwords=set(nltk_stopwords.words('english') + nltk_stopwords.words('russian') + extra_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenzer for vectorizer\n",
    "def delete_non_letters(words):\n",
    "    new_words = []\n",
    "    words = words.split(' ')\n",
    "    for word in words:\n",
    "        new_word = \"\".join(c for c in word if c.isalpha())\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    new_words = ' '.join(new_words)\n",
    "    return new_words\n",
    "\n",
    "def tokenize(sent):\n",
    "    \n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r'\\d+', '', sent)\n",
    "    sent = delete_non_letters(sent)\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    \n",
    "    return sent\n",
    "    \n",
    "\n",
    "def tf_idf(docs):\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words=stopwords, smooth_idf=False,  lowercase=False)\n",
    "    tfidf.fit(docs)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf_idf(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = tf_idf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_thresh = 2.\n",
    "upper_thresh = 7.\n",
    "not_often = idfs > lower_thresh\n",
    "not_rare = idfs < upper_thresh\n",
    "\n",
    "mask = not_often * not_rare\n",
    "\n",
    "good_words = np.array(tf_idf.get_feature_names())[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of original vocabulary: 110476\n",
      "After filtering: 720\n"
     ]
    }
   ],
   "source": [
    "cleaned = []\n",
    "for word in good_words:\n",
    "    word = re.sub(\"^(\\d+\\w*$|_+)\", \"\", word)\n",
    "    \n",
    "    if len(word) == 0:\n",
    "        continue\n",
    "    cleaned.append(word)\n",
    "print(\"Len of original vocabulary: %d\\nAfter filtering: %d\"%(idfs.shape[0], len(cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a803b684d7664939bf054058ead8dad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=720), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After stemming: 485\n"
     ]
    }
   ],
   "source": [
    "#stemmin russian words and ignorin english\n",
    "m = Mystem()\n",
    "stemmed = set()\n",
    "voc_len = len(cleaned)\n",
    "for i in tqdm(range(voc_len)):\n",
    "    word = cleaned.pop()\n",
    "    stemmed_word = m.lemmatize(word)[0]\n",
    "    stemmed.add(stemmed_word)\n",
    "    \n",
    "stemmed = list(stemmed)\n",
    "print('After stemming: %d'%(len(stemmed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = {word : i for i,word in enumerate(stemmed)}\n",
    "\n",
    "count_vect = CountVectorizer(tokenizer=tokenize,\n",
    "                             stop_words=stopwords,\n",
    "                             vocabulary=voc)\n",
    "\n",
    "dataset = count_vect.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18449x485 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24799 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=30,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=0, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA(n_components=10, learning_method=\"batch\", max_iter=30, random_state=0)\n",
    "lda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_topics = lda.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (10, 485)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ruslan_Golubev\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "момент        вчера         фото          интересно     завтра        \n",
      "важно         ребята        дома          осень         пусть         \n",
      "цель          опыт          круто         скоро         история       \n",
      "список        както         ко            метро         точно         \n",
      "прямо         читать        репост        питер         привет        \n",
      "мама          гдето         месяц         участие       наверное      \n",
      "необходимо    го            сайт          проект        среди         \n",
      "интервью      какойто       спб           настроение    рад           \n",
      "план          помощь        курс          санктпетербургвместо        \n",
      "столько       количество    игра          активный      наконецто     \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "чтото         ктото         видео         фильм         любовь        \n",
      "поэтому       возможность   км            кино          х             \n",
      "например      мозг          море          онлайн        сердце        \n",
      "возможно      многие        лето          подарок       кофе          \n",
      "либо          ура           впервые       внимание      играть        \n",
      "равно         уровень       домой         использовать  песня         \n",
      "кстати        вроде         сильно        начало        вк            \n",
      "внутри        вконтакте     путешествие   главное       сезон         \n",
      "пост          благодаря     настолько     открытие      быстро        \n",
      "решение       школа         интернет      сша           нормально     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.argsort(document_topics[:, 9])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3268, 15484, 17900, ..., 18309,  5779, 17810], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я принял участие в голосовании «Лучший книжный магазин Москвы – 2019: выбор активных граждан» в проекте «Активный гражданин» и получил 20 баллов'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[17900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я принялa участие в голосовании «Лучший книжный магазин Москвы – 2019: выбор активных граждан» в проекте «Активный гражданин» и получилa 20 баллов'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[3268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
